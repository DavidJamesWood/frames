# frames
This project takes video files (most common types) and splits them into frames using pachyderm.
Steps to run:
1. create a pachyderm repo with: pachctl create repo videos
2. add videos files to this repo with: pachctl put file videos@master:<name-of-file> -f <path-to-file>
3. create the pipeline with: pachctl create pipeline -f https://raw.githubusercontent.com/DavidJamesWood/frames/master/frames.json
  
Blog Header: Data Scientists/Engineers, Here's how to increase your value with open source pachyderm!

  Creating predictive models is no longer a rare skill with the advent of data science "get smart quick" courses. So how can you stand out in front of the other data professionals? The answer is to incorporate organizational stability, auditability, and simple scalability into your AI pipelines. These virtues are of high importance to the modern day corporation, but are after thoughts by most data science practitioners. Let's run through how pachyderm enables the three virtues.
1. Organizational Stability: Most companies looking for a tools like pachyderm are deficient in data talent. Most data scientists have the ability to take an extant dataset and create a useful model, but many are lacking in the ability to bring a pipeline and model into production. With both of these aspects in play, many projects sputter at the transition from development to production. I can either go through the trouble of teaching your company what a data engineer is and why they need one, which may create organizational instability. Many managers might think, "Why are our other engineers insufficient?" Another option is to supplement data pipelining skills with a tool such as pachyderm. (queue all of the great data pipeline features)   
2. Auditability: Recently, there has been a large amount of AI development in the financial sector. Many data professionals from outside of the financial sector are not ready for the hurdles that financial regulations produce. A marketing company does not have to keep track of why there model sent one person a blue newsletter and another a red newsletter, but an insurance carrier must maintain the history of their descisions in a manner which can be audited. As financial corporations start using streaming data, social media, complicated models, and frequently updated models the need for a tool like pachyderm becomes essential. (queue data change management and storage features)  
3. Infrastructure Scalability: The cost for cloud resources has plummeted, while technology continues to evolve. Many corporations still maintain ineffective on-prem solutions. Corporations are risk adverse, so until you can prove that your solution can handle the projected influx of data at a reasonable price, you are not going to gain any real traction in removing the weight of on-prem systems and protocols. Senior members have been gone through years of over priced and under scheduled IT projects. Pachyderm infrastructure cost scales linearly and at a minimal price because it takes advantage of (queue tech...docker, kubernettes, etc).  

Here is an interesting tutorial that I would be interested in putting together. Create a machine learning model that recognizes when a mammal enters a wildlife live stream. There are hundreds of live cameras placed in the wilderness, many used for research purposes. My guess is that a majority of the footage is useless and some person has to sit there and go through every stream and 'cut' the footage. I would gather thousands of images of mammals in the wild as well as pictures of nature, that are labeled, and create a deep learning model for mammal detection. The productionalization of this process would be a good test for pachyderm since it would have hundreds of live inputs. And the output difference of having a majority of non action to having clips of action in sequence would be visually compelling. 
